{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRKgZ3BQ1VIC6Y9uUvH2FX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grkmkcgl/globalai_bootcamp_project/blob/main/GlobalAI_Project_DataPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bu kısımları kendi bilgisayarlarımızdan spyder kullanarak yaptık. Spyder total çıktısı en aşağıda yer alıyor"
      ],
      "metadata": {
        "id": "8kD6J6JU_NFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kütüphanelerin import edilmesi**"
      ],
      "metadata": {
        "id": "hrkx__J_j1ws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bAGfpE6JiS_"
      },
      "outputs": [],
      "source": [
        "import librosa.feature\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import cv2 as cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verilerin colab'e indirilmesi**"
      ],
      "metadata": {
        "id": "ZKfC3Bs0kKW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz -O urban8k.tgz\n",
        "!tar -xzf urban8k.tgz\n",
        "!rm urban8k.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnVKgSKZJoIZ",
        "outputId": "e0144a41-29a1-4cab-e0cb-696b4e9c3e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-24 12:12:14--  https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6023741708 (5.6G) [application/octet-stream]\n",
            "Saving to: ‘urban8k.tgz’\n",
            "\n",
            "urban8k.tgz         100%[===================>]   5.61G  20.4MB/s    in 4m 5s   \n",
            "\n",
            "2022-09-24 12:16:21 (23.4 MB/s) - ‘urban8k.tgz’ saved [6023741708/6023741708]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectogramların oluşturulması (Bu kısmı spyder üzerinden kendi bilgisayarlarımızdan yaptık çünkü veri dosyasını upload etmesi çok uzun sürüyordu)**"
      ],
      "metadata": {
        "id": "_by4hjfWj4fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spectrogram(y):\n",
        "    spec = librosa.feature.melspectrogram(y=y)\n",
        "    spec_conv = librosa.amplitude_to_db(spec, ref=np.max)\n",
        "    return spec_conv\n",
        "\n",
        "directory = 'UrbanSound8K/audio'\n",
        "\n",
        "\n",
        "# Create spectograms and save figures in folders\n",
        "\n",
        "for foldername in os.listdir(directory):\n",
        "    folder = os.path.join(directory, foldername)\n",
        "    if os.path.isdir(folder):\n",
        "        audiofolder = folder[19:]\n",
        "        print(audiofolder)\n",
        "        os.mkdir(f\"CreatedSpectrograms/{audiofolder}\")\n",
        "        for audio in os.listdir(folder):\n",
        "            file = os.path.join(folder, audio)\n",
        "            if os.path.isfile(file):\n",
        "                if not file.endswith(\".DS_Store\"):\n",
        "                    signal, sr = librosa.load(file)\n",
        "                    spectrogram = create_spectrogram(signal)\n",
        "                    np.shape(spectrogram)\n",
        "                    hop_length = 512\n",
        "                    n_fft = 2048\n",
        "                    plt.figure(figsize=(8, 7))\n",
        "                    librosa.display.specshow(spectrogram, sr=sr, cmap=\"magma\", hop_length=hop_length)\n",
        "                    plt.savefig(f\"CreatedSpectrograms/{audiofolder}/{audio[:-4]}.png\")\n",
        "                    plt.close()"
      ],
      "metadata": {
        "id": "r2oX_o0zyVpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectogramların resim listesine dönüştürülmesi, sınıfıyla birlikte kaydedilmesi ve veri setine dönüştürülmesi**"
      ],
      "metadata": {
        "id": "JKDZ5lwskROW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Gereksiz kolonları silme\n",
        "directory = \"spectrograms\"\n",
        "data = pd.read_csv(\"UrbanSound8K.csv\")\n",
        "data.drop(['fsID', 'start', 'end', 'salience', 'fold', 'class', 'slice_file_name'], inplace=True, axis=1)\n",
        "data.sort_values(by='classID', inplace = True)\n",
        "data.reset_index(inplace = True)\n",
        "data.drop(['index'], inplace=True, axis=1)\n",
        "\n",
        "# Resimler ve etiketler için boş liste oluşturma\n",
        "list_of_specs_list = []\n",
        "row = 0\n",
        "\n",
        "for foldername in os.listdir(directory):\n",
        "    folder = os.path.join(directory, foldername)\n",
        "    print(\"folder\", foldername, \"analyzing has started\")\n",
        "    if os.path.isdir(folder):\n",
        "        for spec in os.listdir(folder):\n",
        "            image = os.path.join(folder, spec)\n",
        "            # resmi okuma ve grayscale çevirme\n",
        "            image = cv2.imread(image)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            # resmi 32,32,1 boyutlandırma\n",
        "            image = cv2.resize(image, (32, 32))\n",
        "            image = np.array(image, dtype=np.float64)\n",
        "            image = np.expand_dims(image, -1)\n",
        "            # normalize etme\n",
        "            image /= 255\n",
        "            # class'ını alıp kaydetme\n",
        "            classID = data.iloc[row:row+1, 0:1].values\n",
        "            classID = np.array(classID, dtype='uint8')\n",
        "            row +=  1\n",
        "            list_of_specs_list.append([image,classID])\n",
        "\n",
        "print(\"DONE CONVERTING TO LIST\")\n",
        "\n",
        "# veriyi karıştırma\n",
        "random.shuffle(list_of_specs_list)"
      ],
      "metadata": {
        "id": "PJTjKeS6l1u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Veri setlerinin csv dosyasına dönüştürülmesi**"
      ],
      "metadata": {
        "id": "-sPDyWFWn4YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "classes = []\n",
        "\n",
        "for image, classID in list_of_specs_list:\n",
        "    images.append(image)\n",
        "    classes.append(classID)\n",
        "\n",
        "# np arraye dönüştürme\n",
        "images = np.array(images).reshape(-1, 32, 32, 1)\n",
        "\n",
        "\n",
        "# train test split oluşturma\n",
        "X_train, X_temporary, y_train, y_temporary = train_test_split(images, classes, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temporary, y_temporary, train_size=0.5)\n",
        "\n",
        "\n",
        "# dataları csv ye kaydetme\n",
        "shaped_arr = np.array(X_train).reshape(-1, 32)\n",
        "shaped_arr = pd.DataFrame(shaped_arr)\n",
        "shaped_arr.to_csv(\"X_train.csv\", index=False, compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
        "\n",
        "shaped_arr = np.array(X_test).reshape(-1, 32)\n",
        "shaped_arr = pd.DataFrame(shaped_arr)\n",
        "shaped_arr.to_csv(\"X_test.csv\", index=False, compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
        "\n",
        "shaped_arr = np.array(X_val).reshape(-1, 32)\n",
        "shaped_arr = pd.DataFrame(shaped_arr)\n",
        "shaped_arr.to_csv(\"X_val.csv\", index=False, compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
        "\n",
        "shaped_arr = np.array(y_train).reshape(-1, 32)\n",
        "shaped_arr = pd.DataFrame(shaped_arr)\n",
        "shaped_arr.to_csv(\"y_train.csv\", index=False, compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
        "\n",
        "shaped_arr = np.array(y_test).reshape(-1, 32)\n",
        "shaped_arr = pd.DataFrame(shaped_arr)\n",
        "shaped_arr.to_csv(\"y_test.csv\", index=False, compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
        "\n",
        "shaped_arr = np.array(y_val).reshape(-1, 32)\n",
        "shaped_arr = pd.DataFrame(shaped_arr)\n",
        "shaped_arr.to_csv(\"y_val.csv\", index=False, compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})"
      ],
      "metadata": {
        "id": "YWTx8C29n4qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUTPUT:\n",
        "\n",
        "folder 0 analyzing has started\n",
        "\n",
        "folder 1 analyzing has started\n",
        "\n",
        "folder 2 analyzing has started\n",
        "\n",
        "folder 3 analyzing has started\n",
        "\n",
        "folder 4 analyzing has started\n",
        "\n",
        "folder 5 analyzing has started\n",
        "\n",
        "folder 6 analyzing has started\n",
        "\n",
        "folder 7 analyzing has started\n",
        "\n",
        "folder 8 analyzing has started\n",
        "\n",
        "folder 9 analyzing has started\n",
        "\n",
        "DONE CONVERTING TO NESTED LIST"
      ],
      "metadata": {
        "id": "xfhiaHVY_-cA"
      }
    }
  ]
}